{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bilingual Food Recognition and Nutrition Info Tool"
      ],
      "metadata": {
        "id": "eoghd7xdVkNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is a user-friendly application that recognizes food items from images and provides detailed nutritional information in both English and Arabic. Built using Hugging Face's Visual Question Answering (VQA) model and Nutritionix's API, the tool offers a comprehensive analysis of various foods, including calories, protein, carbohydrates, fats, sugars, fiber, sodium, and serving size."
      ],
      "metadata": {
        "id": "cQ3nkSryVl0t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcP5Yt-uYh7o"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUEP2Kg0Ylfk"
      },
      "source": [
        "### Libraries\n",
        "\n",
        "Start by installing and importing necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N9VupHDQTLJ"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install gradio\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6BA9bJ-BYHTB"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import gradio as gr\n",
        "import wget\n",
        "from transformers import pipeline\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hmeVqkneUfX"
      },
      "source": [
        "### API Setup\n",
        "\n",
        "This cell sets up the connection to the Nutritionix API by defining the API URL and the required headers (App ID and App Key)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AixPmXdGeX7c"
      },
      "outputs": [],
      "source": [
        "# Nutritionix API setup\n",
        "api_url = \"https://trackapi.nutritionix.com/v2/natural/nutrients\"\n",
        "\n",
        "# App ID, App Key provided by Nutritionix\n",
        "headers = {\n",
        "    \"x-app-id\": \"dd773727\",\n",
        "    \"x-app-key\": \"86f278fc4c7f276c386f280848acf3e6\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78s83jDWrCMr"
      },
      "source": [
        "### Model Initiates\n",
        "\n",
        "This cell loads the pre-trained models required for the project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Pp-1Pc0FrHGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310c7e32-0cbc-4a67-a080-3281b95ecd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "# Load the Models\n",
        "\n",
        "# Load the BLIP VQA Model (Recognize the food)\n",
        "visual_quest_ans = pipeline(\"visual-question-answering\", model=\"Salesforce/blip-vqa-base\")\n",
        "\n",
        "# Load the Translation Model (English to Arabic)\n",
        "translation_eng_to_ar = pipeline(\"translation_en_to_ar\", model=\"marefa-nlp/marefa-mt-en-ar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SowoxKCcsAqF"
      },
      "source": [
        "### Model Functions\n",
        "\n",
        "This cell contains all the essential functions used in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vVd_yuYvtERA"
      },
      "outputs": [],
      "source": [
        "# Function to recognize food from the image using the VQA model\n",
        "def food_recognizer(image):\n",
        "    # Pass the image and the question to the model to identify the food on the image\n",
        "    result = visual_quest_ans(image=image, question=\"What is the food or the drink in the image?\")\n",
        "    return result[0]['answer']\n",
        "\n",
        "# Function to fetch nutritional information from Nutritionix API\n",
        "def nutrition_info(food):\n",
        "    # Prepare the data for the API request\n",
        "    data = {\n",
        "        \"query\": food,\n",
        "        \"timezone\": \"US/Eastern\"\n",
        "    }\n",
        "\n",
        "    # Send a POST request to the Nutritionix API with the food item\n",
        "    response = requests.post(api_url, headers=headers, json=data)\n",
        "\n",
        "    # Get the nutritional information in JSON format\n",
        "    nutritions = response.json()\n",
        "    return nutritions\n",
        "\n",
        "# Function to translate text from English to Arabic with preprocessing\n",
        "def translator(text):\n",
        "    text = text.strip()  # Remove leading/trailing spaces\n",
        "    result = translation_eng_to_ar(text) # Use the translation model to translate the text\n",
        "    result = result[0]['translation_text']\n",
        "    return result\n",
        "\n",
        "# Function to process food recognition and get nutrition info\n",
        "def process_food_result(image, language):\n",
        "    # Recognize the food item in the uploaded image\n",
        "    food_item = food_recognizer(image)\n",
        "\n",
        "    # Fetch nutritional information for the recognized food item\n",
        "    nutritions_info = nutrition_info(food_item)\n",
        "\n",
        "    # Extract nutritional information\n",
        "    food_info = nutritions_info['foods'][0]\n",
        "    calories = food_info['nf_calories']\n",
        "    protein = food_info['nf_protein']\n",
        "    carbs = food_info['nf_total_carbohydrate']\n",
        "    fat = food_info['nf_total_fat']\n",
        "    # Use 'Unknown' if value is not available\n",
        "    sugars = food_info.get('nf_sugars', 'Unknown')\n",
        "    fiber = food_info.get('nf_dietary_fiber', 'Unknown')\n",
        "    sodium = food_info.get('nf_sodium', 'Unknown')\n",
        "    serving_size = food_info.get('serving_weight_grams', 'Unknown')\n",
        "\n",
        "    # Identify if the food item is a liquid (simple check for common drink categories)\n",
        "    liquid_keywords = ['juice', 'water', 'milk', 'soda', 'tea', 'coffee']\n",
        "    is_liquid = any(keyword in food_item.lower() for keyword in liquid_keywords)\n",
        "\n",
        "    # Convert serving size to milliliters if it's a liquid\n",
        "    if is_liquid and serving_size != 'Unknown':\n",
        "        serving_size_ml = serving_size  # Assume 1 gram ≈ 1 milliliter for liquids\n",
        "        serving_size_text_en = f\"{serving_size_ml} mL\"\n",
        "        serving_size_text_ar = f\"{serving_size_ml} مل\"\n",
        "    else:\n",
        "        serving_size_text_en = f\"{serving_size} grams\"\n",
        "        serving_size_text_ar = f\"{serving_size} جرام\"\n",
        "\n",
        "    # Generate output in the selected language\n",
        "    if language == \"Arabic\":\n",
        "        # Translate the food item name to Arabic\n",
        "        food_item_ar = translator(food_item)\n",
        "        output_ar = f\"\"\"\n",
        "        <div style='direction: rtl; text-align: right;'>\n",
        "            <b>الطعام</b>: {food_item_ar}<br>\n",
        "            <b>حجم الحصة</b>: {serving_size_text_ar}<br>\n",
        "            <b>السعرات الحرارية</b>: {calories} كيلو كالوري<br>\n",
        "            <b>البروتين</b>: {protein} جرام<br>\n",
        "            <b>الكربوهيدرات</b>: {carbs} جرام<br>\n",
        "            <b>السكر</b>: {sugars} جرام<br>\n",
        "            <b>الألياف</b>: {fiber} جرام<br>\n",
        "            <b>الصوديوم</b>: {sodium} مجم<br>\n",
        "            <b>الدهون</b>: {fat} جرام\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        return output_ar\n",
        "    else:\n",
        "       # For English output\n",
        "        output_en = f\"\"\"\n",
        "        <div style='text-align: left;'>\n",
        "            <b>Food</b>: {food_item}<br>\n",
        "            <b>Serving Size</b>: {serving_size_text_en}<br>\n",
        "            <b>Calories</b>: {calories} kcal<br>\n",
        "            <b>Protein</b>: {protein}g<br>\n",
        "            <b>Carbohydrates</b>: {carbs}g<br>\n",
        "            <b>Sugars</b>: {sugars}g<br>\n",
        "            <b>Fiber</b>: {fiber}g<br>\n",
        "            <b>Sodium</b>: {sodium}mg<br>\n",
        "            <b>Fat</b>: {fat}g\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        return output_en\n",
        "\n",
        "\n",
        "# Gradio interface function\n",
        "def gradio_function(image, language):\n",
        "    # Call the process_food_result function to get the output\n",
        "    result = process_food_result(image, language)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Images\n",
        "\n",
        "This cell downloads example images using the wget library."
      ],
      "metadata": {
        "id": "Lx2I2G0ibOpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define URLs of example images\n",
        "image_urls = [\n",
        "    \"https://raw.githubusercontent.com/Abdulrahman078/ML_Datasets-Imgs-Vids/main/close-up-delicious-pizza.jpg\",\n",
        "    \"https://raw.githubusercontent.com/Abdulrahman078/ML_Datasets-Imgs-Vids/main/assorted-desserts-with-chocolate-frosted-pink-glazed-sprinkles.jpg\",\n",
        "    \"https://raw.githubusercontent.com/Abdulrahman078/ML_Datasets-Imgs-Vids/main/fried-fish-with-cranberries-wooden-board.jpg\",\n",
        "    \"https://raw.githubusercontent.com/Abdulrahman078/ML_Datasets-Imgs-Vids/main/glass-water.jpg\"\n",
        "]\n",
        "\n",
        "# Download the images and use their paths\n",
        "example_images = [wget.download(url) for url in image_urls]\n"
      ],
      "metadata": {
        "id": "9HomBcf0bRHu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_OxuX7azUPf"
      },
      "source": [
        "### Gradio Setup\n",
        "\n",
        "This cell sets up the Gradio interface for the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "6fK60PY7zWcs",
        "outputId": "9161fcc0-804a-4334-c56e-9fb09cded33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f814e829f1b5a38cbb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f814e829f1b5a38cbb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f814e829f1b5a38cbb.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Setup the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_function, # Function to call\n",
        "    inputs=[gr.Image(type=\"pil\", label=\"Upload an image\"), # Input: Image (in PIL format)\n",
        "            gr.Dropdown(choices=[\"Arabic\", \"English\"], label=\"Select Language\", value=\"Arabic\")], # Input: Dropdown for language selection\n",
        "    outputs=gr.HTML(label=\"Food and Nutrition Information\"), # Output: HTML for displaying nutrition info\n",
        "    title=\"Bilingual Food Recognition and Nutrition Info Tool\", # Title of the Gradio interface\n",
        "    description=\"Upload an image of food, and the tool will recognize it and provide nutritional information in both English or Arabic languages.\", # Description of the tool\n",
        "    examples=[[img] for img in example_images]  # Add examples with the image and language\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface with debug mode enabled\n",
        "iface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}